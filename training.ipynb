{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "378f6043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46eba64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "365c5826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1eb2616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f14d125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d80939e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453f3b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a2ba2a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "import torchmetrics as tm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54203b6",
   "metadata": {},
   "source": [
    "## Step 1: Loading the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd24dc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = Path(\"data/ESC-50-master\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59227807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "177037dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv(datapath / Path(\"meta/esc50.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68df58bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "      <th>esc10</th>\n",
       "      <th>src_file</th>\n",
       "      <th>take</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-100032-A-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dog</td>\n",
       "      <td>True</td>\n",
       "      <td>100032</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-100038-A-14.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>chirping_birds</td>\n",
       "      <td>False</td>\n",
       "      <td>100038</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-100210-A-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-100210-B-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-101296-A-19.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>False</td>\n",
       "      <td>101296</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  fold  target        category  esc10  src_file take\n",
       "0   1-100032-A-0.wav     1       0             dog   True    100032    A\n",
       "1  1-100038-A-14.wav     1      14  chirping_birds  False    100038    A\n",
       "2  1-100210-A-36.wav     1      36  vacuum_cleaner  False    100210    A\n",
       "3  1-100210-B-36.wav     1      36  vacuum_cleaner  False    100210    B\n",
       "4  1-101296-A-19.wav     1      19    thunderstorm  False    101296    A"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8662bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, sr = torchaudio.load(datapath / 'audio' / csv.iloc[0,0], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccc17496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 40000])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchaudio.transforms.Resample(orig_freq=sr, new_freq=8000)(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c97394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torchaudio.transforms.MelSpectrogram(sample_rate=sr)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdb01524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 1103])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2df5b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torchaudio.transforms.AmplitudeToDB()(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16e7d042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14bfa3e9850>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(h[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "554b348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESC20Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path: Path =  Path(\"data/ESC-50-master\"), sample_rate: int = 8000, folds = [1]):\n",
    "        self.path = path\n",
    "        self.csv = pd.read_csv(path / Path(\"meta/esc50.csv\"))\n",
    "        self.csv = self.csv[self.csv['fold'].isin(folds)]\n",
    "        self.resample = torchaudio.transforms.Resample(orig_freq=44100, new_freq=sample_rate)\n",
    "        self.melspec = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate)\n",
    "        self.db = torchaudio.transforms.AmplitudeToDB()\n",
    "    def __getitem__(self, index):\n",
    "        row = self.csv.iloc[index]\n",
    "        wav, _ = torchaudio.load(self.path / 'audio' / row['filename'])\n",
    "        label = row['target']\n",
    "        xb = self.db(self.melspec(self.resample(wav)))\n",
    "        return xb, label\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2da3fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ESC20Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "266244fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 201])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_data:\n",
    "    break\n",
    "print(xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd86262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ESC20Dataset(folds = [1])\n",
    "val_data = ESC20Dataset(folds = [2])\n",
    "test_data = ESC20Dataset(folds = [3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7a1d760",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data,batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1de6922",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_data,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "763e70f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_data,batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3287ff8e",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a9df45fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioNet(pl.LightningModule):\n",
    " \n",
    "    def __init__(self, n_classes = 50, base_filters = 64):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, base_filters, 11, padding=5)\n",
    "        self.bn1 = nn.BatchNorm2d(base_filters)\n",
    "        self.conv2 = nn.Conv2d(base_filters, base_filters, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(base_filters)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv3 = nn.Conv2d(base_filters, base_filters * 2, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(base_filters * 2)\n",
    "        self.conv4 = nn.Conv2d(base_filters * 2, base_filters * 4, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(base_filters * 4)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(base_filters * 4, n_classes)\n",
    "        self.valid_acc = tm.Accuracy()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = self.fc1(x[:, :, 0, 0])\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch, batch_index):\n",
    "        x,y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat,y)\n",
    "        self.log('train_loss',loss, on_step = True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_index):\n",
    "        x,y = batch\n",
    "        y_hat = self(x)\n",
    "        y_hat = torch.argmax(y_hat, dim = 1)\n",
    "        self.valid_acc(y_hat, y)\n",
    "        self.log('val_acc',self.valid_acc, on_epoch = True, prog_bar = True)\n",
    "        return self.valid_acc\n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr = 1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d81fe051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "948cffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audionet = AudioNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "011b28ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 50])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_loader))\n",
    "audionet(xb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a7386470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus= 1, max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7a3e0960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type        | Params\n",
      "-------------------------------------------\n",
      "0  | conv1     | Conv2d      | 7.8 K \n",
      "1  | bn1       | BatchNorm2d | 128   \n",
      "2  | conv2     | Conv2d      | 36.9 K\n",
      "3  | bn2       | BatchNorm2d | 128   \n",
      "4  | pool1     | MaxPool2d   | 0     \n",
      "5  | conv3     | Conv2d      | 73.9 K\n",
      "6  | bn3       | BatchNorm2d | 256   \n",
      "7  | conv4     | Conv2d      | 295 K \n",
      "8  | bn4       | BatchNorm2d | 512   \n",
      "9  | pool2     | MaxPool2d   | 0     \n",
      "10 | fc1       | Linear      | 12.8 K\n",
      "11 | valid_acc | Accuracy    | 0     \n",
      "-------------------------------------------\n",
      "427 K     Trainable params\n",
      "0         Non-trainable params\n",
      "427 K     Total params\n",
      "1.711     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cecco\\Anaconda3\\envs\\thesis\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "C:\\Users\\cecco\\Anaconda3\\envs\\thesis\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ed61832fed40dca90f8906425dd871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(audionet,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5c2e584a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cecco\\Anaconda3\\envs\\thesis\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:99: UserWarning: you passed in a test_dataloader but have no test_step. Skipping test loop\n",
      "  rank_zero_warn(f\"you passed in a {loader_name} but have no {step_name}. Skipping {stage} loop\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(audionet,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf99334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d514e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
